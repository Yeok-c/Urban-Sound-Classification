{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 9305\n",
      "Number of validation samples: 2326\n",
      "Number of test samples: 2326\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load portion of the TF cat_vs_dogs dataset\n",
    "# tfds.disable_progress_bar()\n",
    "train_ds, validation_ds, test_ds = tfds.load(\n",
    "    \"cats_vs_dogs\",\n",
    "    # Reserve 10% for validation and 10% for test\n",
    "    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n",
    "    as_supervised=True,  # Include labels\n",
    ")\n",
    "\n",
    "print(\"Number of training samples: %d\" % tf.data.experimental.cardinality(train_ds))\n",
    "print(\"Number of validation samples: %d\" % tf.data.experimental.cardinality(validation_ds))\n",
    "print(\"Number of test samples: %d\" % tf.data.experimental.cardinality(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# from models import models\n",
    "\n",
    "### Train and evaluate via 10-Folds cross-validation ###\n",
    "accuracies = []\n",
    "folds = np.array(['fold1','fold2','fold3','fold4',\n",
    "                'fold5','fold6','fold7','fold8',\n",
    "                'fold9','fold10'])\n",
    "load_dir = \"../UrbanSounds8K/processed/\"\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(folds):\n",
    "    x_train, y_train = [], []\n",
    "    for ind in train_index:\n",
    "        # read features or segments of an audio file\n",
    "        train_data = np.load(\"{0}/{1}.npz\".format(load_dir,folds[ind]), \n",
    "                    allow_pickle=True)\n",
    "        # for training stack all the segments so that they are treated as an example/instance\n",
    "        features = np.concatenate(train_data[\"features\"], axis=0) \n",
    "        labels = np.concatenate(train_data[\"labels\"], axis=0)\n",
    "        x_train.append(features)\n",
    "        y_train.append(labels)\n",
    "\n",
    "    # stack x,y pairs of all training folds \n",
    "    x_train = np.concatenate(x_train, axis = 0).astype(np.float32)\n",
    "    y_train = np.concatenate(y_train, axis = 0).astype(np.float32)\n",
    "    \n",
    "    # for testing we will make predictions on each segment and average them to \n",
    "    # produce single label for an entire sound clip.\n",
    "    test_data = np.load(\"{0}/{1}.npz\".format(load_dir,\n",
    "                folds[test_index][0]), allow_pickle=True)\n",
    "    x_test = test_data[\"features\"]\n",
    "    y_test = test_data[\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "test_data = np.load(\"../UrbanSounds8K/processed_vgg/fold1.npz\".format(load_dir,\n",
    "        folds[test_index][0]), allow_pickle=True)\n",
    "\n",
    "x_test = test_data[\"features\"]\n",
    "y_test = test_data[\"labels\"]\n",
    "\n",
    "# features = np.concatenate(train_data[\"features\"], axis=0) \n",
    "# labels = np.concatenate(train_data[\"labels\"], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (1, 128), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "x_test_ = np.array(list(chain.from_iterable(x_test)))\n",
    "# type(x_test_)\n",
    "arg = tf.convert_to_tensor(x_test_, dtype=tf.float32)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(arg)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "# Get the data from https://www.kaggle.com/kongaevans/speaker-recognition-dataset/download\n",
    "# and save it to the 'Downloads' folder in your HOME directory\n",
    "DATASET_ROOT = os.path.join(os.path.expanduser(\"~\"), \"Downloads/16000_pcm_speeches\")\n",
    "\n",
    "# The folders in which we will put the audio samples and the noise samples\n",
    "AUDIO_SUBFOLDER = \"audio\"\n",
    "NOISE_SUBFOLDER = \"noise\"\n",
    "\n",
    "DATASET_AUDIO_PATH = os.path.join(DATASET_ROOT, AUDIO_SUBFOLDER)\n",
    "DATASET_NOISE_PATH = os.path.join(DATASET_ROOT, NOISE_SUBFOLDER)\n",
    "\n",
    "# Percentage of samples to use for validation\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "# Seed to use when shuffling the dataset and the noise\n",
    "SHUFFLE_SEED = 43\n",
    "\n",
    "# The sampling rate to use.\n",
    "# This is the one used in all of the audio samples.\n",
    "# We will resample all of the noise to this sampling rate.\n",
    "# This will also be the output size of the audio wave samples\n",
    "# (since all samples are of 1 second long)\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# The factor to multiply the noise with according to:\n",
    "#   noisy_sample = sample + noise * prop * scale\n",
    "#      where prop = sample_amplitude / noise_amplitude\n",
    "SCALE = 0.5\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted numpy array into tensor:\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [3 4 5]\n",
      " [5 6 7]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1,2,3],[3,4,5],[5,6,7]])\n",
    "tensor = tf.convert_to_tensor(array)\n",
    "print(\"Converted numpy array into tensor:\")\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "print(type(dataset))\n",
    "# print(list(dataset.as_numpy_iterator()))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aef9c008b311f0b7f3d27d4f3907c3c9c136ad861e53efda71f92a04d644c5c8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('usc39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
